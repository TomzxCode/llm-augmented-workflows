# Implementation Plan: Generate a plan using multiple models

**Issue:** #4 - Generate a plan using multiple models
**Status:** Feasible
**Complexity:** High
**Estimated Scope:** Major architectural changes required

## Problem Statement

Currently, the plan generation system is tightly coupled to Anthropic's Claude Code Action and only uses a single model for plan generation. The goal is to support:

1. **Multiple model providers** (OpenAI, Anthropic, Google, etc.)
2. **Multiple models per provider** (e.g., GPT-4, Claude Sonnet, Gemini Pro)
3. **Different prompts for the same model** (e.g., different developer role perspectives)
4. **Aggregation strategy** to combine multiple plan outputs

## Feasibility Assessment

✅ **Feasible** - This can be implemented, but requires significant architectural changes:

**Challenges:**
- The current system uses `anthropics/claude-code-action@v1` which is Claude-specific
- Different providers have different API formats, tool calling conventions, and token limits
- Need to handle authentication for multiple providers
- Need a strategy to combine multiple plan outputs into a coherent final plan
- GitHub Actions has execution time limits (max 6 hours per job)

**Opportunities:**
- The command system (`.claude/commands/`) provides good separation of concerns
- The workflow structure is already modular
- Can leverage existing GitHub Actions for different providers
- Can run multiple models in parallel using matrix strategy

## Proposed Solution

### Architecture Overview

Replace the single-model approach with a **multi-model orchestration system**:

```
GitHub Issue Event
    ↓
Orchestrator Workflow (claude-plan.yml)
    ↓
Model Strategy Selection (config-driven)
    ↓
Parallel Model Execution (matrix strategy)
    ├── Anthropic Model(s)
    ├── OpenAI Model(s)
    └── Google Model(s)
    ↓
Plan Aggregation Step
    ↓
Create Single Unified Plan PR
```

### Implementation Steps

#### Phase 1: Configuration System

**1.1 Create Model Configuration File**

File: `.claude/models.yml`

```yaml
# Model provider definitions
providers:
  anthropic:
    enabled: true
    api_key_secret: ANTHROPIC_API_KEY
    oauth_token_secret: CLAUDE_CODE_OAUTH_TOKEN
    models:
      - id: claude-sonnet-4-5
        name: Claude Sonnet 4.5
        use_code_action: true  # Use claude-code-action
        max_tokens: 8192
      - id: claude-opus-4-5
        name: Claude Opus 4.5
        use_code_action: true
        max_tokens: 8192

  openai:
    enabled: true
    api_key_secret: OPENAI_API_KEY
    models:
      - id: gpt-4-turbo
        name: GPT-4 Turbo
        max_tokens: 4096
      - id: gpt-4o
        name: GPT-4o
        max_tokens: 4096

  google:
    enabled: false  # Can be enabled when ready
    api_key_secret: GOOGLE_API_KEY
    models:
      - id: gemini-2.0-flash-exp
        name: Gemini 2.0 Flash
        max_tokens: 8192

# Strategy definitions
strategies:
  diverse:
    description: "Use different models from different providers"
    models:
      - provider: anthropic
        model: claude-sonnet-4-5
        prompt_variant: default
      - provider: openai
        model: gpt-4-turbo
        prompt_variant: default

  role-based:
    description: "Use same model with different role-based prompts"
    models:
      - provider: anthropic
        model: claude-sonnet-4-5
        prompt_variant: architect
      - provider: anthropic
        model: claude-sonnet-4-5
        prompt_variant: security-engineer
      - provider: anthropic
        model: claude-sonnet-4-5
        prompt_variant: test-engineer

  consensus:
    description: "Use multiple models for consensus"
    models:
      - provider: anthropic
        model: claude-sonnet-4-5
        prompt_variant: default
      - provider: anthropic
        model: claude-opus-4-5
        prompt_variant: default
      - provider: openai
        model: gpt-4o
        prompt_variant: default

# Default strategy
default_strategy: diverse
```

**1.2 Create Prompt Variants Configuration**

File: `.claude/prompt-variants.yml`

```yaml
variants:
  default:
    description: "Standard plan generation approach"
    file: ".claude/commands/generate-plan.md"

  architect:
    description: "Focus on architecture and system design"
    file: ".claude/commands/generate-plan-architect.md"
    additional_instructions: |
      Focus on:
      - System architecture and component design
      - Design patterns and architectural patterns
      - Scalability and maintainability
      - Module boundaries and interfaces

  security-engineer:
    description: "Focus on security implications"
    file: ".claude/commands/generate-plan-security.md"
    additional_instructions: |
      Focus on:
      - Security vulnerabilities and threats
      - Authentication and authorization
      - Data protection and encryption
      - Input validation and sanitization
      - OWASP Top 10 considerations

  test-engineer:
    description: "Focus on testing strategy"
    file: ".claude/commands/generate-plan-testing.md"
    additional_instructions: |
      Focus on:
      - Test coverage and strategy
      - Edge cases and error scenarios
      - Integration and end-to-end testing
      - Test maintainability
      - Performance testing needs
```

#### Phase 2: Multi-Provider Execution System

**2.1 Create Provider Adapter Scripts**

File: `.github/scripts/run-model.sh`

```bash
#!/bin/bash
# Script to run a specific model and generate a plan
# Usage: run-model.sh <provider> <model> <prompt_variant> <issue_number> <repo>

set -e

PROVIDER=$1
MODEL=$2
PROMPT_VARIANT=$3
ISSUE_NUMBER=$4
REPO=$5

OUTPUT_DIR="plans/multi-model/$ISSUE_NUMBER"
mkdir -p "$OUTPUT_DIR"

# Provider-specific execution
case "$PROVIDER" in
  anthropic)
    echo "Running Anthropic model: $MODEL"
    # Use claude-code-action or direct API call
    ;;
  openai)
    echo "Running OpenAI model: $MODEL"
    # Use OpenAI API with custom script
    ;;
  google)
    echo "Running Google model: $MODEL"
    # Use Google API with custom script
    ;;
  *)
    echo "Unknown provider: $PROVIDER"
    exit 1
    ;;
esac
```

**2.2 Create OpenAI Provider Implementation**

File: `.github/scripts/providers/openai-provider.py`

```python
#!/usr/bin/env python3
"""
OpenAI provider for plan generation.
Mimics the behavior of claude-code-action but using OpenAI models.
"""

import os
import json
import sys
from openai import OpenAI

def main():
    api_key = os.environ.get('OPENAI_API_KEY')
    model = os.environ.get('MODEL')
    issue_number = os.environ.get('ISSUE_NUMBER')
    repo = os.environ.get('REPO')
    prompt_file = os.environ.get('PROMPT_FILE')

    if not all([api_key, model, issue_number, repo, prompt_file]):
        print("Missing required environment variables")
        sys.exit(1)

    client = OpenAI(api_key=api_key)

    # Read prompt template
    with open(prompt_file, 'r') as f:
        prompt_content = f.read()

    # Fetch issue details (similar to what Claude does)
    # ... implementation ...

    # Generate plan using OpenAI
    # ... implementation with function calling for tools ...

    # Save plan to output file
    # ... implementation ...

if __name__ == '__main__':
    main()
```

**2.3 Create Google Provider Implementation**

File: `.github/scripts/providers/google-provider.py`

Similar structure to OpenAI provider but using Google's Gemini API.

#### Phase 3: Update Workflow for Multi-Model Execution

**3.1 Update `.github/workflows/claude-plan.yml`**

Key changes:
1. Read model configuration
2. Use matrix strategy to run models in parallel
3. Collect all outputs
4. Run aggregation step

```yaml
name: Generate Plan (Multi-Model)

on:
  issues:
    types: [opened, labeled]

jobs:
  check-labels:
    # ... existing label checking logic ...

  load-config:
    name: Load Model Configuration
    runs-on: ubuntu-latest
    needs: check-labels
    if: needs.check-labels.outputs.should_run == 'true'
    outputs:
      strategy: ${{ steps.parse-config.outputs.strategy }}
      models: ${{ steps.parse-config.outputs.models }}
    steps:
      - uses: actions/checkout@v4
      - name: Parse model configuration
        id: parse-config
        run: |
          # Read .claude/models.yml
          # Parse the default strategy
          # Output matrix configuration for models
          echo "models=$(cat .claude/models.yml | yq eval '.strategies.diverse.models' -o json)" >> $GITHUB_OUTPUT

  generate-plans:
    name: Generate Plan - ${{ matrix.provider }}/${{ matrix.model }}
    runs-on: ubuntu-latest
    needs: load-config
    strategy:
      matrix:
        include: ${{ fromJson(needs.load-config.outputs.models) }}
      max-parallel: 5  # Run up to 5 models in parallel
      fail-fast: false  # Continue even if one model fails

    steps:
      - uses: actions/checkout@v4

      # Anthropic models using claude-code-action
      - name: Generate plan with Claude
        if: matrix.provider == 'anthropic'
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          prompt: |
            /generate-plan
            REPO=${{ github.repository }}
            ISSUE_NUMBER=${{ needs.check-labels.outputs.issue_number }}
            PROMPT_VARIANT=${{ matrix.prompt_variant }}
            OUTPUT_PREFIX=${{ matrix.provider }}-${{ matrix.model }}

      # OpenAI models using custom script
      - name: Generate plan with OpenAI
        if: matrix.provider == 'openai'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MODEL: ${{ matrix.model }}
          ISSUE_NUMBER: ${{ needs.check-labels.outputs.issue_number }}
          REPO: ${{ github.repository }}
          PROMPT_VARIANT: ${{ matrix.prompt_variant }}
        run: |
          python .github/scripts/providers/openai-provider.py

      # Google models using custom script
      - name: Generate plan with Google
        if: matrix.provider == 'google'
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          MODEL: ${{ matrix.model }}
          ISSUE_NUMBER: ${{ needs.check-labels.outputs.issue_number }}
          REPO: ${{ github.repository }}
          PROMPT_VARIANT: ${{ matrix.prompt_variant }}
        run: |
          python .github/scripts/providers/google-provider.py

      - name: Upload plan artifact
        uses: actions/upload-artifact@v4
        with:
          name: plan-${{ matrix.provider }}-${{ matrix.model }}-${{ matrix.prompt_variant }}
          path: plans/multi-model/${{ needs.check-labels.outputs.issue_number }}/${{ matrix.provider }}-${{ matrix.model }}-${{ matrix.prompt_variant }}.md
          retention-days: 7

  aggregate-plans:
    name: Aggregate Plans
    runs-on: ubuntu-latest
    needs: [check-labels, generate-plans]
    steps:
      - uses: actions/checkout@v4

      - name: Download all plan artifacts
        uses: actions/download-artifact@v4
        with:
          path: plans/multi-model/${{ needs.check-labels.outputs.issue_number }}/
          pattern: plan-*
          merge-multiple: true

      - name: Aggregate plans
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          prompt: |
            /aggregate-plans
            REPO=${{ github.repository }}
            ISSUE_NUMBER=${{ needs.check-labels.outputs.issue_number }}
            PLANS_DIR=plans/multi-model/${{ needs.check-labels.outputs.issue_number }}

      - name: Create Plan PR
        # ... existing PR creation logic ...
```

#### Phase 4: Plan Aggregation System

**4.1 Create Plan Aggregation Command**

File: `.claude/commands/aggregate-plans.md`

```markdown
---
description: Aggregate multiple plan outputs into a single coherent plan
allowed-tools: Read,Write,Bash(gh:*),Bash(git:*)
---

# Task: Aggregate Multiple Plans

You are given multiple implementation plans generated by different models or prompt variants for the same GitHub issue. Your task is to create a single, unified implementation plan that:

1. **Synthesizes the best ideas** from all plans
2. **Identifies consensus areas** where all models agree
3. **Highlights divergent approaches** where models disagree
4. **Resolves conflicts** by choosing the most feasible approach
5. **Maintains coherence** with a single narrative voice

## Steps

1. Read all plan files from the PLANS_DIR environment variable
2. Analyze each plan for:
   - Proposed architecture
   - Implementation steps
   - Risk assessments
   - Testing strategies
   - Estimated complexity
3. Create a synthesis that:
   - Uses the most thorough feasibility assessment
   - Combines the best architectural insights
   - Merges implementation steps (deduplicating similar ones)
   - Highlights unique concerns raised by any model
   - Notes where models disagreed and your resolution
4. Write the final plan to `plans/{ISSUE_NUMBER}.md`
5. Include a meta-section documenting:
   - Which models were consulted
   - Areas of consensus
   - Areas of disagreement and resolution rationale

## Plan Structure

Use the standard plan format from generate-plan.md, but add:

### Plan Generation Metadata

**Models Consulted:**
- Model A: [provider/model/variant]
- Model B: [provider/model/variant]
- ...

**Synthesis Notes:**
- **Consensus areas:** [what all models agreed on]
- **Divergent approaches:** [where models disagreed]
- **Resolution rationale:** [why you chose certain approaches over others]
- **Unique insights:** [notable ideas from specific models]

[Rest of standard plan structure...]
```

#### Phase 5: Testing and Documentation

**5.1 Create Test Strategy**

File: `tests/test-multi-model.yml` (workflow for testing)

```yaml
name: Test Multi-Model Plan Generation

on:
  workflow_dispatch:
    inputs:
      test_issue_number:
        description: 'Test issue number'
        required: true
      strategy:
        description: 'Strategy to test'
        required: true
        type: choice
        options:
          - diverse
          - role-based
          - consensus

jobs:
  test-multi-model:
    runs-on: ubuntu-latest
    steps:
      # Test the multi-model workflow with a specific strategy
      # ...
```

**5.2 Update Documentation**

Files to update:
- `README.md` - Add section on multi-model support
- `CLAUDE.md` - Update workflow guidelines
- Create `docs/MULTI_MODEL_GUIDE.md` - Comprehensive guide for:
  - How to configure models
  - How to create prompt variants
  - How to choose strategies
  - How aggregation works
  - Troubleshooting

#### Phase 6: Gradual Rollout

**6.1 Feature Flag System**

Add to `.claude/models.yml`:

```yaml
features:
  multi_model_enabled: false  # Set to true to enable
  fallback_to_single_model: true  # If multi-model fails, use single
  default_single_model:
    provider: anthropic
    model: claude-sonnet-4-5
```

**6.2 Backward Compatibility**

Keep the original `claude-plan.yml` workflow and:
- Rename it to `claude-plan-single.yml`
- Create new `claude-plan-multi.yml` for multi-model
- Use a workflow dispatch or configuration to choose which to use
- Eventually migrate fully to multi-model once stable

## Implementation Sequence

1. **Phase 1** (Configuration) - Low risk, establishes foundation
2. **Phase 2** (Provider Adapters) - Can be built incrementally per provider
3. **Phase 3** (Workflow Updates) - Start with feature flag disabled
4. **Phase 4** (Aggregation) - Critical for multi-model to be useful
5. **Phase 5** (Testing) - Validate with real issues
6. **Phase 6** (Rollout) - Enable gradually with monitoring

## Edge Cases and Risks

### Edge Cases to Handle

1. **Model failures**: One model times out or errors
   - Solution: Use `fail-fast: false` in matrix strategy
   - Aggregator should handle missing plans gracefully

2. **Conflicting recommendations**: Models suggest incompatible approaches
   - Solution: Aggregator uses predefined rules (e.g., prefer simpler approach)
   - Document the conflict in the final plan

3. **Rate limits**: Hitting API rate limits for providers
   - Solution: Add retry logic with exponential backoff
   - Stagger requests or use lower `max-parallel` setting

4. **Cost management**: Multiple models increase API costs
   - Solution: Make strategy configurable per repository
   - Allow per-issue override with labels (e.g., `multi-model-enabled`)

5. **Execution time**: Multiple models may exceed GitHub Actions timeout
   - Solution: Set reasonable timeouts per model (30-45 min)
   - Use faster models for role-based variants

### Risks

1. **Complexity**: System becomes harder to debug and maintain
   - Mitigation: Good logging, clear documentation, incremental rollout

2. **Inconsistent outputs**: Aggregation may produce incoherent plans
   - Mitigation: Extensive testing, human review of first plans
   - Refine aggregation prompts based on results

3. **Provider dependencies**: Relies on multiple external services
   - Mitigation: Fallback to single model, retry logic, alerts

4. **Secret management**: Need API keys for multiple providers
   - Mitigation: GitHub Secrets, document setup clearly

## Testing Plan

1. **Unit tests** for provider adapters (if using scripts)
2. **Integration tests** with test issues
3. **Manual validation** of first 5-10 aggregated plans
4. **Comparison studies**: Single vs multi-model plan quality
5. **Performance testing**: Execution time and cost analysis

## Success Metrics

- Plans generated successfully with multiple models (>90% success rate)
- Aggregated plans are coherent and actionable (human evaluation)
- Execution time stays under 1 hour for typical issues
- Cost per plan stays within reasonable budget (define threshold)
- User feedback indicates improved plan quality

## Alternative Approaches Considered

### Alternative 1: Sequential Model Execution
Run models one at a time, each seeing previous outputs.
- **Pros**: Can build on each other's insights
- **Cons**: Much slower, creates dependencies
- **Decision**: Rejected - parallel is faster and avoids groupthink

### Alternative 2: Single Model, Multiple Passes
Use one model but run it multiple times with different prompts.
- **Pros**: Simpler, fewer dependencies
- **Cons**: Misses diversity of different model training
- **Decision**: Keep as "role-based" strategy option

### Alternative 3: Post-Processing Only
Generate single plan, then use other models to review/enhance it.
- **Pros**: Simpler workflow, faster
- **Cons**: Review models constrained by initial plan
- **Decision**: Could be future enhancement (review phase)

## Open Questions

1. **Which strategy should be default?**
   - Recommendation: Start with "diverse" for maximum variety
   - Allow per-repo configuration

2. **How to handle disagreements in aggregation?**
   - Recommendation: Document all approaches, choose based on feasibility + simplicity
   - Could add voting system (majority wins)

3. **Should aggregation use a specific model or be configurable?**
   - Recommendation: Use Claude Opus (highest capability) for aggregation
   - Make configurable in future

4. **What's the budget/cost tolerance?**
   - Needs input from repository owner
   - Can limit strategies or models based on budget

## Dependencies

- GitHub Secrets for API keys: `OPENAI_API_KEY`, `GOOGLE_API_KEY`, `ANTHROPIC_API_KEY`
- Python environment with `openai`, `google-generativeai` packages
- `yq` tool for YAML parsing in workflows
- Adequate GitHub Actions minutes quota

## Conclusion

This implementation is **feasible but complex**. It requires:
- Significant workflow restructuring
- Provider adapter implementations
- Robust aggregation logic
- Careful testing and rollout

The value proposition is **high** if the aggregated plans are indeed better quality than single-model plans. This should be validated early in the rollout.

**Recommendation**: Start with Phase 1 (configuration) and Phase 4 (aggregation command) to establish the foundation, then incrementally add provider support starting with the easiest one (likely Anthropic since infrastructure exists).
